{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Input\n",
    "from keras.layers import LSTM, SpatialDropout1D \n",
    "from sklearn.model_selection import train_test_split\n",
    "import csv\n",
    "import keras\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import os\n",
    "from getcpuinfo import cpuinfo\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTrainedLSTMModel(maxLengthParam):\n",
    "    \n",
    "    model = Sequential()\n",
    "    \n",
    "    #model.add(SpatialDropout1D(0.3))\n",
    "    \n",
    "    model.add(LSTM((50),dropout = 0.3,batch_input_shape = (None,maxLengthParam,1), return_sequences = True))\n",
    "    \n",
    "    model.add(Dense(50, activation = 'tanh'))\n",
    "    \n",
    "    #model.add(SpatialDropout1D(0.3))\n",
    "    \n",
    "    model.add(LSTM(25,return_sequences = False))\n",
    "    \n",
    "    model.add(Dense(3, activation='softmax'))\n",
    "    \n",
    "    model.compile(loss = 'categorical_crossentropy', optimizer = 'adam',metrics = ['accuracy'])\n",
    "    \n",
    "    if os.path.isfile(\"LSTMBestWeights.hdf5\"):\n",
    "        \n",
    "        #print(\"Hey\")\n",
    "        \n",
    "        model.load_weights(\"LSTMBestWeights.hdf5\")\n",
    "        \n",
    "        return model\n",
    "    else:\n",
    "        \n",
    "        print(\"Unable to find trained model\")\n",
    "        \n",
    "        return -1;\n",
    "    \n",
    "    \n",
    "def getTrained3OuptutModel(maxLengthParam):\n",
    "    \n",
    "    model = Sequential()\n",
    "    \n",
    "    #model.add(SpatialDropout1D(0.3))\n",
    "    \n",
    "    model.add(Flatten(batch_input_shape = (None,maxLengthParam,1)))\n",
    "    \n",
    "    model.add(Dense(50, activation = \"relu\"))\n",
    "    \n",
    "    model.add(Dropout(0.3, noise_shape=None, seed=None))\n",
    "    \n",
    "    model.add(Dense(25, activation = 'relu'))\n",
    "    \n",
    "    model.add(Dropout(0.3, noise_shape=None, seed=None))\n",
    "    \n",
    "    #model.add(SpatialDropout1D(0.3))\n",
    "    \n",
    "    model.add(Dense(12,activation = 'relu'))\n",
    "    \n",
    "    model.add(Dropout(0.3, noise_shape=None, seed=None))\n",
    "    \n",
    "    model.add(Dense(6,activation = 'relu'))\n",
    "    \n",
    "    model.add(Dropout(0.3, noise_shape=None, seed=None))\n",
    "    \n",
    "    model.add(Dense(3, activation='softmax'))\n",
    "    \n",
    "    model.compile(loss = 'categorical_crossentropy', optimizer = 'adam',metrics = ['accuracy'])\n",
    "    \n",
    "    if os.path.isfile(\"3OutputDNNBestWeights.hdf5\"):\n",
    "        \n",
    "        #print(\"Hey\")\n",
    "        \n",
    "        model.load_weights(\"3OutputDNNBestWeights.hdf5\")\n",
    "        \n",
    "        print(\"Returning Trained Model\")\n",
    "        \n",
    "        return model\n",
    "    else:\n",
    "        \n",
    "        print(\"Unable to find trained model\")\n",
    "        \n",
    "        return -1;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def appendToList(oldList,newList,maxLength):\n",
    "    \n",
    "    #append to the new entries\n",
    "    oldList = np.insert(oldList,0,np.array([newList]),axis = 0)\n",
    "    \n",
    "    #Remove oldest row if there are more than 50 entries\n",
    "    if(oldList.shape[0]>maxLength):\n",
    "        oldList = oldList[:49,:]\n",
    "\n",
    "    return oldList\n",
    "\n",
    "def getPredictionsForOneTimeStep(model,usageList,maxLengthParam):\n",
    "    \n",
    "    currUsageList = cpuinfo()\n",
    "    \n",
    "    updatedList = appendToList(usageList,currUsageList,maxLengthParam)\n",
    "    \n",
    "    predictions = []\n",
    "    \n",
    "    predDict = {0:0,1:1,2:-1}\n",
    "    \n",
    "    for i in range(updatedList.shape[1]):\n",
    "        \n",
    "        if updatedList.shape[0]==maxLengthParam:\n",
    "            \n",
    "            modelOutput = model.predict(np.expand_dims(np.expand_dims(updatedList[:,i],axis = 1),axis = 0))\n",
    "\n",
    "            modelPrediction = predDict[np.argmax(modelOutput)]\n",
    "\n",
    "            predictions.append(modelPrediction)\n",
    "        \n",
    "        else:\n",
    "            \n",
    "            predictions.append(0)\n",
    "    \n",
    "    return predictions, updatedList\n",
    "\n",
    "#overProvisionedList = \n",
    "\n",
    "def getRightOutputs(usageList,minThreshold, maxThreshold):\n",
    "    \n",
    "    currList = usageList[0,:]\n",
    "    print(currList)\n",
    "    \n",
    "    target = []\n",
    "    \n",
    "    for i in range(usageList.shape[1]):\n",
    "        if currList[i] > maxThreshold:# Scale Up\n",
    "            #print(\"MaxThres \",maxThreshold,\" \",currList[i])\n",
    "            target.append(1)\n",
    "        elif currList[i] < minThreshold: # Scale Down\n",
    "            #print(\"MinThres \",minThreshold,\" \",currList[i])\n",
    "            target.append(-1)\n",
    "        else:\n",
    "            #print(\"Same \",currList[i])\n",
    "            target.append(0)  #Remain same\n",
    "    \n",
    "    return target\n",
    "\n",
    "\n",
    "def generatePredictions(model, maxLengthParam,containerCount,minThreshold, maxThreshold):\n",
    "    \n",
    "    usageArray = np.empty(shape = (0,containerCount))\n",
    "    \n",
    "    cnt = 0;\n",
    "    \n",
    "    correctOutputArray = np.empty(shape = (0,containerCount))\n",
    "    \n",
    "    predictionsArray = np.empty(shape = (0,containerCount))\n",
    "    \n",
    "    while cnt<80:\n",
    "        \n",
    "        predictions,usageArray = getPredictionsForOneTimeStep(model,usageArray,maxLengthParam)\n",
    "        \n",
    "        predictionsArray = appendToList(predictionsArray, predictions, maxLengthParam)\n",
    "        \n",
    "        if(usageArray.shape[0]==maxLengthParam):\n",
    "    \n",
    "            correctOutputsList = getRightOutputs(usageArray,minThreshold, maxThreshold)\n",
    "\n",
    "            correctOutputArray = appendToList(correctOutputArray, correctOutputsList, maxLengthParam)\n",
    "            \n",
    "            print(\"Predictions: \",predictions)\n",
    "            print(\"Expected Outputs: \",correctOutputsList)\n",
    "            print(accuracy_score(predictions,correctOutputsList))\n",
    "            \n",
    "            #for i in range(usageArray.shape[1]):\n",
    "\n",
    "                #correctOutputsForTraining = to_categorical(correctOutputs,num_classes = 3)\n",
    "        \n",
    "        cnt+=1\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "LSTMModel = getTrainedLSTMModel(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 6.2048594 15.4269942  0.        41.6213113  4.9339693]\n",
      "Predictions:  [-1, -1, -1, -1, -1]\n",
      "Expected Outputs:  [-1, -1, -1, 0, -1]\n",
      "0.8\n",
      "[ 6.2048594 15.4269942  0.        41.6213113  4.8244155]\n",
      "Predictions:  [-1, -1, -1, -1, -1]\n",
      "Expected Outputs:  [-1, -1, -1, 0, -1]\n",
      "0.8\n",
      "[ 6.1120891 14.5741581  0.        42.3681654  4.8244155]\n",
      "Predictions:  [-1, -1, -1, -1, -1]\n",
      "Expected Outputs:  [-1, -1, -1, 0, -1]\n",
      "0.8\n",
      "[ 6.1120891 12.8007786  0.        39.5758704  4.7088931]\n",
      "Predictions:  [-1, -1, -1, -1, -1]\n",
      "Expected Outputs:  [-1, -1, -1, 0, -1]\n",
      "0.8\n",
      "[ 5.3150079 12.8007786  0.        39.5758704  4.7088931]\n",
      "Predictions:  [-1, -1, -1, -1, -1]\n",
      "Expected Outputs:  [-1, -1, -1, 0, -1]\n",
      "0.8\n",
      "[ 5.3150079 12.8007786  0.        39.5758704  4.7088931]\n",
      "Predictions:  [-1, -1, -1, -1, -1]\n",
      "Expected Outputs:  [-1, -1, -1, 0, -1]\n",
      "0.8\n",
      "[ 5.3150079 13.3291659  0.        37.317058   4.5659639]\n",
      "Predictions:  [-1, -1, -1, -1, -1]\n",
      "Expected Outputs:  [-1, -1, -1, 0, -1]\n",
      "0.8\n",
      "[ 5.3847789 13.3291659  0.        37.317058   4.5659639]\n",
      "Predictions:  [-1, -1, -1, -1, -1]\n",
      "Expected Outputs:  [-1, -1, -1, 0, -1]\n",
      "0.8\n",
      "[ 5.3847789 12.4687433  0.        37.317058   4.5659639]\n",
      "Predictions:  [-1, -1, -1, -1, -1]\n",
      "Expected Outputs:  [-1, -1, -1, 0, -1]\n",
      "0.8\n",
      "[ 5.3847789 12.4687433  0.        38.7573183  4.4382227]\n",
      "Predictions:  [-1, -1, -1, -1, -1]\n",
      "Expected Outputs:  [-1, -1, -1, 0, -1]\n",
      "0.8\n",
      "[ 5.3847789 12.4687433  0.        38.7573183  4.4382227]\n",
      "Predictions:  [-1, -1, -1, -1, -1]\n",
      "Expected Outputs:  [-1, -1, -1, 0, -1]\n",
      "0.8\n",
      "[ 6.7585838 13.7454057  0.        38.7573183  4.4382227]\n",
      "Predictions:  [-1, -1, -1, -1, -1]\n",
      "Expected Outputs:  [-1, -1, -1, 0, -1]\n",
      "0.8\n",
      "[ 6.7585838 13.7454057  0.        40.211898   4.6340246]\n",
      "Predictions:  [-1, -1, -1, -1, -1]\n",
      "Expected Outputs:  [-1, -1, -1, 0, -1]\n",
      "0.8\n",
      "[ 5.2990052 13.7454057  0.        40.211898   4.6340246]\n",
      "Predictions:  [-1, -1, -1, -1, -1]\n",
      "Expected Outputs:  [-1, -1, -1, 0, -1]\n",
      "0.8\n",
      "[ 5.2990052 13.7454057  0.        40.211898   5.0278436]\n",
      "Predictions:  [-1, -1, -1, 0, -1]\n",
      "Expected Outputs:  [-1, -1, -1, 0, -1]\n",
      "1.0\n",
      "[ 5.2990052 13.932403   0.        40.211898   5.0278436]\n",
      "Predictions:  [-1, -1, -1, 0, -1]\n",
      "Expected Outputs:  [-1, -1, -1, 0, -1]\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "temp = cpuinfo()\n",
    "generatePredictions(LSTMModel,50,len(temp),30,70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mylist = np.array([cpuinfo()])\n",
    "print(mylist)\n",
    "print(mylist.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mylist2 = np.insert(mylist,0, np.array([cpuinfo()]), axis = 0)\n",
    "print(mylist2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mylist = np.append(np.empty(shape = (0,5)), np.array([cpuinfo()]), axis = 0)\n",
    "print(mylist)\n",
    "print(mylist.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mylist[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [1,2,3,4]\n",
    "a[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = np.random.randint(1,100,size = (10,5))\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.expand_dims(np.expand_dims(b[:,1],axis = 1),axis = 0).shape\n",
    "#b[:,1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p36)",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
