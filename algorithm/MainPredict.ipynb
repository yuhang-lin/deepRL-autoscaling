{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Input\n",
    "from keras.layers import LSTM, SpatialDropout1D \n",
    "from sklearn.model_selection import train_test_split\n",
    "import csv\n",
    "import keras\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import os\n",
    "#from getcpuinfo import cpuinfo\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.insert(0, os.path.abspath('..'))\n",
    "from infra.getcpuinfo import cpuinfo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTrainedLSTMModel(maxLengthParam):\n",
    "    \n",
    "    model = Sequential()\n",
    "    \n",
    "    #model.add(SpatialDropout1D(0.3))\n",
    "    \n",
    "    model.add(LSTM((50),dropout = 0.3,batch_input_shape = (None,maxLengthParam,1), return_sequences = True))\n",
    "    \n",
    "    model.add(Dense(50, activation = 'tanh'))\n",
    "    \n",
    "    #model.add(SpatialDropout1D(0.3))\n",
    "    \n",
    "    model.add(LSTM(25,return_sequences = False))\n",
    "    \n",
    "    model.add(Dense(3, activation='softmax'))\n",
    "    \n",
    "    model.compile(loss = 'categorical_crossentropy', optimizer = 'adam',metrics = ['accuracy'])\n",
    "    \n",
    "    if os.path.isfile(\"LSTMBestWeights.hdf5\"):\n",
    "        \n",
    "        #print(\"Hey\")\n",
    "        \n",
    "        model.load_weights(\"LSTMBestWeights.hdf5\")\n",
    "        \n",
    "        return model\n",
    "    else:\n",
    "        \n",
    "        print(\"Unable to find trained model\")\n",
    "        \n",
    "        return -1;\n",
    "    \n",
    "    \n",
    "def getTrained3OuptutModel(maxLengthParam):\n",
    "    \n",
    "    model = Sequential()\n",
    "    \n",
    "    #model.add(SpatialDropout1D(0.3))\n",
    "    \n",
    "    model.add(Flatten(batch_input_shape = (None,maxLengthParam,1)))\n",
    "    \n",
    "    model.add(Dense(50, activation = \"relu\"))\n",
    "    \n",
    "    model.add(Dropout(0.3, noise_shape=None, seed=None))\n",
    "    \n",
    "    model.add(Dense(25, activation = 'relu'))\n",
    "    \n",
    "    model.add(Dropout(0.3, noise_shape=None, seed=None))\n",
    "    \n",
    "    #model.add(SpatialDropout1D(0.3))\n",
    "    \n",
    "    model.add(Dense(12,activation = 'relu'))\n",
    "    \n",
    "    model.add(Dropout(0.3, noise_shape=None, seed=None))\n",
    "    \n",
    "    model.add(Dense(6,activation = 'relu'))\n",
    "    \n",
    "    model.add(Dropout(0.3, noise_shape=None, seed=None))\n",
    "    \n",
    "    model.add(Dense(3, activation='softmax'))\n",
    "    \n",
    "    model.compile(loss = 'categorical_crossentropy', optimizer = 'adam',metrics = ['accuracy'])\n",
    "    \n",
    "    if os.path.isfile(\"3OutputDNNBestWeights.hdf5\"):\n",
    "        \n",
    "        #print(\"Hey\")\n",
    "        \n",
    "        model.load_weights(\"3OutputDNNBestWeights.hdf5\")\n",
    "        \n",
    "        print(\"Returning Trained Model\")\n",
    "        \n",
    "        return model\n",
    "    else:\n",
    "        \n",
    "        print(\"Unable to find trained model\")\n",
    "        \n",
    "        return -1;\n",
    "    \n",
    "def getTrainedRL3OutputDNN(historyParam):\n",
    "    \n",
    "    usageInputLayer = keras.layers.Input(shape=(historyParam,1))\n",
    "    \n",
    "    flattened_layer = keras.layers.Flatten()(usageInputLayer)\n",
    "    \n",
    "    fullyConnected_0 = keras.layers.Dense(125, activation = 'relu',\n",
    "                    kernel_initializer='he_normal', kernel_regularizer=regularizers.l2(0.1))(flattened_layer)\n",
    "    \n",
    "    fullyConnected_1 = keras.layers.Dense(100, activation = 'relu',\n",
    "                    kernel_initializer='he_normal', kernel_regularizer=regularizers.l2(0.1))(fullyConnected_0)\n",
    "    \n",
    "    #drop1 = keras.layers.Dropout(0.25)(fullyConnected_1)\n",
    "    fullyConnected_2 = keras.layers.Dense(75, activation = 'relu',\n",
    "                    kernel_initializer='he_normal', kernel_regularizer=regularizers.l2(0.1))(fullyConnected_1)\n",
    "    \n",
    "    #drop2 = keras.layers.Dropout(0.25)(fullyConnected_2)\n",
    "    fullyConnected_3 = keras.layers.Dense(50, activation = 'relu',\n",
    "                    kernel_initializer='he_normal', kernel_regularizer=regularizers.l2(0.1))(fullyConnected_2)\n",
    "    \n",
    "    fullyConnected_4 = keras.layers.Dense(25, activation = 'relu',\n",
    "                    kernel_initializer='he_normal', kernel_regularizer=regularizers.l2(0.1))(fullyConnected_3)\n",
    "    \n",
    "    fullyConnected_5 = keras.layers.Dense(12, activation = 'relu',\n",
    "                    kernel_initializer='he_normal', kernel_regularizer=regularizers.l2(0.1))(fullyConnected_4)\n",
    "    \n",
    "    fullyConnected_6 = keras.layers.Dense(6, activation = 'relu',\n",
    "                    kernel_initializer='he_normal')(fullyConnected_5)\n",
    "    \n",
    "    softmax_output = keras.layers.Dense(3,activation='softmax')(fullyConnected_5)\n",
    "    \n",
    "    predictionModel = keras.models.Model(inputs=usageInputLayer,outputs=softmax_output)\n",
    "    \n",
    "    if os.path.isfile(\"3OutputRL3BestWeights.hdf5\"):\n",
    "        \n",
    "        #print(\"Hey\")\n",
    "        \n",
    "        predictionModel.load_weights(\"3OutputRL3BestWeights.hdf5\")\n",
    "        \n",
    "        print(\"Returning Trained Model\")\n",
    "        \n",
    "        return predictionModel\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        print(\"Unable to find trained model\")\n",
    "        \n",
    "        return -1;\n",
    "    \n",
    "def getTrainedRLLSTM(historyParam):\n",
    "    \n",
    "    usageInputLayer = keras.layers.Input(shape=(historyParam,1))\n",
    "    \n",
    "    #flattened_layer = keras.layers.Flatten()(usageInputLayer)\n",
    "    \n",
    "    LSTM_1 = keras.layers.LSTM((50), return_sequences = True)(usageInputLayer)\n",
    "    \n",
    "    full_connect_2 = keras.layers.Dense(50, activation = 'relu')(LSTM_1)\n",
    "    \n",
    "    LSTM_3 = keras.layers.LSTM(25, return_sequences = False)(full_connect_2)\n",
    "    \n",
    "    full_connect_3 = keras.layers.Dense(12, activation = 'relu')(LSTM_3)\n",
    "    \n",
    "    full_connect_4 = keras.layers.Dense(6, activation = 'relu')(full_connect_3)\n",
    "    \n",
    "    softmax_output = keras.layers.Dense(3,activation='softmax')(full_connect_4)\n",
    "    \n",
    "    predictionModel = keras.models.Model(inputs=usageInputLayer,outputs=softmax_output)\n",
    "    \n",
    "    if os.path.isfile(\"LSTMV2RLBestWeights.hdf5\"):\n",
    "        \n",
    "        #print(\"Hey\")\n",
    "        \n",
    "        predictionModel.load_weights(\"LSTMV2RLBestWeights.hdf5\")\n",
    "        \n",
    "        print(\"Returning Trained Model\")\n",
    "        \n",
    "        return predictionModel\n",
    "    else:\n",
    "        \n",
    "        print(\"Unable to find trained model\")\n",
    "        \n",
    "        return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def appendToList(oldList,newList,maxLength):\n",
    "    \n",
    "    #append to the new entries\n",
    "    oldList = np.insert(oldList,0,np.array([newList]),axis = 0)\n",
    "    \n",
    "    #Remove oldest row if there are more than 50 entries\n",
    "    if(oldList.shape[0]>maxLength):\n",
    "        oldList = oldList[:49,:]\n",
    "\n",
    "    return oldList\n",
    "\n",
    "def getPredictionsForOneTimeStep(model,usageList,maxLengthParam):\n",
    "    \n",
    "    currUsageList = cpuinfo()\n",
    "    \n",
    "    updatedList = appendToList(usageList,currUsageList,maxLengthParam)\n",
    "    \n",
    "    predictions = []\n",
    "    \n",
    "    predDict = {0:0,1:1,2:-1}\n",
    "    \n",
    "    for i in range(updatedList.shape[1]):\n",
    "        \n",
    "        if updatedList.shape[0]==maxLengthParam:\n",
    "            \n",
    "            modelOutput = model.predict(np.expand_dims(np.expand_dims(updatedList[:,i],axis = 1),axis = 0))\n",
    "\n",
    "            modelPrediction = predDict[np.argmax(modelOutput)]\n",
    "\n",
    "            predictions.append(modelPrediction)\n",
    "        \n",
    "        else:\n",
    "            \n",
    "            predictions.append(0)\n",
    "    \n",
    "    return predictions, updatedList\n",
    "\n",
    "#overProvisionedList = \n",
    "\n",
    "def getRightOutputs(usageList,minThreshold, maxThreshold):\n",
    "    \n",
    "    currList = usageList[0,:]\n",
    "    print(currList)\n",
    "    \n",
    "    target = []\n",
    "    \n",
    "    for i in range(usageList.shape[1]):\n",
    "        if currList[i] > maxThreshold:# Scale Up\n",
    "            #print(\"MaxThres \",maxThreshold,\" \",currList[i])\n",
    "            target.append(1)\n",
    "        elif currList[i] < minThreshold: # Scale Down\n",
    "            #print(\"MinThres \",minThreshold,\" \",currList[i])\n",
    "            target.append(-1)\n",
    "        else:\n",
    "            #print(\"Same \",currList[i])\n",
    "            target.append(0)  #Remain same\n",
    "    \n",
    "    return target\n",
    "\n",
    "def getVirtualMachineCPU():\n",
    "    \n",
    "    availableVirtualMachineCPU = 10\n",
    "    \n",
    "    return availableVirtualMachineCPU\n",
    "\n",
    "def getPercentagesBasedOnPredictions(predictions, usageArray, minThreshold, maxThreshold):\n",
    "    \n",
    "    underProvisionedContainers = [i for i in range(usageArray[0,:].shape[1])  if usageArray[0,i]>maxThreshold]\n",
    "    \n",
    "    overProvisionedContainers = [i for i in range(usageArray[0,:].shape[1])  if usageArray[0,i]<minThreshold]\n",
    "    \n",
    "    rightlyProvisionedContainers = [i for i in range(usageArray[0,:].shape[1])  if usageArray[0,i]>=minThreshold and usageArray[0,i]<=maxThreshold]\n",
    "    \n",
    "    availableVCPU = getVirtualMachineCPU()\n",
    "    \n",
    "    VCPUSplit = 0\n",
    "    \n",
    "    percentArray = np.zeros(len(predictions))\n",
    "    \n",
    "    if len(overProvisionedContainers)>0:\n",
    "        \n",
    "        availableVCPU = availableVCPU + len(overProvisionedContainers) * 10\n",
    "        \n",
    "        for i in overProvisionedContainers:\n",
    "            \n",
    "            percentArray[i] = -10\n",
    "    \n",
    "    #if len(rightlyProvisioned)>0:\n",
    "        #availableVCPU = availableVCPU + len(rightlyProvisioned) * 5\n",
    "        \n",
    "    if availableVCPU>0 and len(underProvisionedContainers)>0:\n",
    "        \n",
    "        if len(underProvisionedContainers)*10>availableVCPU:\n",
    "            \n",
    "            for i in rightlyProvisionedContainers:\n",
    "                \n",
    "                percentArray[i] = -5\n",
    "                \n",
    "                availableVCPU += 5\n",
    "                \n",
    "                if (availableVCPU < len(underProvisionedContainers)*10):\n",
    "                    \n",
    "                    break\n",
    "        \n",
    "            VCPUSplit = availableVCPU/len(underProvisionedContainers)\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            VCPUSplit = 10\n",
    "        \n",
    "        for i in underProvisionedContainers:\n",
    "                \n",
    "                percentArray[i] = VCPUSplit\n",
    "        \n",
    "    \n",
    "    return percentArray\n",
    "        \n",
    "\n",
    "def callAPIWithPredictions(predictions,URL):\n",
    "\n",
    "    headers = {\n",
    "        'Content-Type': 'application/json',\n",
    "    }\n",
    "\n",
    "    data = '{\"predictions\":['+ ','.join(str(num) for num in predictions) +']}'\n",
    "    print(data)\n",
    "    response = requests.post(URL, headers=headers, data=data)\n",
    "    \n",
    "    \n",
    "def generatePredictions(model, maxLengthParam,containerCount,minThreshold, maxThreshold):\n",
    "    \n",
    "    usageArray = np.empty(shape = (0,containerCount))\n",
    "    \n",
    "    cnt = 0;\n",
    "    \n",
    "    correctOutputArray = np.empty(shape = (0,containerCount))\n",
    "    \n",
    "    predictionsArray = np.empty(shape = (0,containerCount))\n",
    "    \n",
    "    while cnt<80:\n",
    "        \n",
    "        predictions,usageArray = getPredictionsForOneTimeStep(model,usageArray,maxLengthParam)\n",
    "        \n",
    "        predictionsArray = appendToList(predictionsArray, predictions, maxLengthParam)\n",
    "        \n",
    "        \n",
    "        if(usageArray.shape[0]==maxLengthParam):\n",
    "    \n",
    "            correctOutputsList = getRightOutputs(usageArray,minThreshold, maxThreshold)\n",
    "\n",
    "            correctOutputArray = appendToList(correctOutputArray, correctOutputsList, maxLengthParam)\n",
    "            \n",
    "            print(\"Predictions: \",predictions)\n",
    "            \n",
    "            print(\"Expected Outputs: \",correctOutputsList)\n",
    "            \n",
    "            callAPIWithPredictions(predictions,\"http://152.46.19.96:5000/changeVCPU\")\n",
    "            \n",
    "            print(accuracy_score(predictions,correctOutputsList))\n",
    "            \n",
    "            #percentArray = getPercentagesBasedOnPredictions(predictions,usageArray,minThreshold, maxThreshold)\n",
    "            \n",
    "            #print(\"Percentage Changes\",percentArray)\n",
    "            #for i in range(usageArray.shape[1]):\n",
    "\n",
    "                #correctOutputsForTraining = to_categorical(correctOutputs,num_classes = 3)\n",
    "        \n",
    "        cnt+=1\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Returning Trained Model\n"
     ]
    }
   ],
   "source": [
    "LSTMModel = getTrainedLSTMModel(50)\n",
    "RLLSTMModel = getTrainedRLLSTM(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 1 column 1 (char 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-aabef168e294>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtemp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcpuinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mgeneratePredictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLSTMModel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m70\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/724/code/deeprl/infra/getcpuinfo.py\u001b[0m in \u001b[0;36mcpuinfo\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0mconinfo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;31m#get cpu info now\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/json/__init__.py\u001b[0m in \u001b[0;36mloads\u001b[0;34m(s, encoding, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    352\u001b[0m             \u001b[0mparse_int\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mparse_float\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m             parse_constant is None and object_pairs_hook is None and not kw):\n\u001b[0;32m--> 354\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_default_decoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    355\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mJSONDecoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/json/decoder.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m         \"\"\"\n\u001b[0;32m--> 339\u001b[0;31m         \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    340\u001b[0m         \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/json/decoder.py\u001b[0m in \u001b[0;36mraw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    355\u001b[0m             \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscan_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mJSONDecodeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Expecting value\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)"
     ]
    }
   ],
   "source": [
    "temp = cpuinfo()\n",
    "generatePredictions(LSTMModel,50,len(temp),30,70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mylist = np.array([cpuinfo()])\n",
    "print(mylist)\n",
    "print(mylist.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mylist2 = np.insert(mylist,0, np.array([cpuinfo()]), axis = 0)\n",
    "print(mylist2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mylist = np.append(np.empty(shape = (0,5)), np.array([cpuinfo()]), axis = 0)\n",
    "print(mylist)\n",
    "print(mylist.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mylist[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [1,2,3,4]\n",
    "a[1:]\n",
    "','.join(str(e) for e in a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = np.random.randint(1,100,size = (10,5))\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.expand_dims(np.expand_dims(b[:,1],axis = 1),axis = 0).shape\n",
    "#b[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.zeros(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p36)",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
