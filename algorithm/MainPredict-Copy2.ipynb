{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Input\n",
    "from keras.layers import LSTM, SpatialDropout1D \n",
    "from sklearn.model_selection import train_test_split\n",
    "import csv\n",
    "import keras\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import os\n",
    "#from getcpuinfo import cpuinfo\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "from apscheduler.schedulers.background import BackgroundScheduler\n",
    "import datetime\n",
    "from keras import regularizers\n",
    "import pandas\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.insert(0, os.path.abspath('..'))\n",
    "from apis.getcpuinfo import cpuinfo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definition for the agent\n",
    "class DQNAgent:\n",
    "    def __init__(self, state_size, action_size):\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "        self.memory = deque(maxlen=2000)\n",
    "        self.gamma = 0.95    # discount rate\n",
    "        self.epsilon = 1.0  # exploration rate\n",
    "        self.epsilon_min = 0.01\n",
    "        self.epsilon_decay = 0.95\n",
    "        self.learning_rate = 0.001\n",
    "        self.model = self._build_model()\n",
    "\n",
    "    def _build_model(self):\n",
    "        # Neural Network for Deep-Q learning Model\n",
    "        model = Sequential()\n",
    "        model.add(Dense(24, input_dim=self.state_size, activation='relu'))\n",
    "        model.add(Dense(12, activation='relu'))\n",
    "        model.add(Dense(6, activation='relu'))\n",
    "        model.add(Dense(self.action_size, activation='linear'))\n",
    "        model.compile(loss='mse',\n",
    "                      optimizer=Adam(lr=self.learning_rate))\n",
    "        print(model.summary())\n",
    "        return model\n",
    "\n",
    "    def remember(self, state, action, reward, next_state, done):\n",
    "        self.memory.append((state, action, reward, next_state, done))\n",
    "\n",
    "    def act(self, state, is_train=True):\n",
    "        if is_train and np.random.rand() <= self.epsilon:\n",
    "            return random.randrange(self.action_size)\n",
    "        act_values = self.model.predict(state)\n",
    "        return np.argmax(act_values[0])  # returns action\n",
    "\n",
    "    def replay(self, batch_size):\n",
    "        minibatch = random.sample(self.memory, batch_size)\n",
    "        for state, action, reward, next_state, done in minibatch:\n",
    "            target = reward\n",
    "            if not done:\n",
    "                target = (reward + self.gamma *\n",
    "                          np.amax(self.model.predict(next_state)[0]))\n",
    "            target_f = self.model.predict(state)\n",
    "            target_f[0][action] = target\n",
    "            self.model.fit(state, target_f, epochs=1, verbose=0)\n",
    "        if self.epsilon > self.epsilon_min:\n",
    "            self.epsilon *= self.epsilon_decay\n",
    "\n",
    "    def load(self, name):\n",
    "        self.model.load_weights(name)\n",
    "\n",
    "    def save(self, name):\n",
    "        self.model.save_weights(name)\n",
    "\n",
    "\n",
    "# Definition for the environment\n",
    "class Environment:\n",
    "    def __init__(self, data):\n",
    "        self.counter = 0\n",
    "        self.window = 50\n",
    "        self.data = data\n",
    "        \n",
    "    def reset(self):\n",
    "        # return the initial state\n",
    "        state = self.data\n",
    "        self.counter = 0\n",
    "        return state\n",
    "    \n",
    "    def get_reward(self, action, next_state):\n",
    "        if np.argmax(self.expected[self.counter - 1]) != action:\n",
    "            return -1\n",
    "        return 1\n",
    "\n",
    "    def step(self, action):\n",
    "        # use the specified action to get the next state\n",
    "        self.counter += 1\n",
    "        done = False\n",
    "        next_state = self.data[self.counter]\n",
    "        reward = self.get_reward(action, next_state)\n",
    "        if (self.counter + 1 == len(self.data)):\n",
    "            done = True\n",
    "        return next_state, reward, done\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDQNModel(maxLengthParam):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(24, input_dim=maxLengthParam, activation='relu'))\n",
    "    model.add(Dense(12, activation='relu'))\n",
    "    model.add(Dense(6, activation='relu'))\n",
    "    model.add(Dense(3, activation='linear'))\n",
    "    model.compile(loss='mse',\n",
    "                  optimizer=Adam(lr=0.001))\n",
    "    if os.path.isfile(\"dqn.h5\"):\n",
    "        model.load_weights(\"dqn.h5\")\n",
    "        return model\n",
    "    else:\n",
    "        print(\"Unable to find trained model\")\n",
    "        return -1;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTrainedLSTMModel(maxLengthParam):\n",
    "    \n",
    "    model = Sequential()\n",
    "    \n",
    "    #model.add(SpatialDropout1D(0.3))\n",
    "    \n",
    "    model.add(LSTM((50),dropout = 0.3,batch_input_shape = (None,maxLengthParam,1), return_sequences = True))\n",
    "    \n",
    "    model.add(Dense(50, activation = 'tanh'))\n",
    "    \n",
    "    #model.add(SpatialDropout1D(0.3))\n",
    "    \n",
    "    model.add(LSTM(25,return_sequences = False))\n",
    "    \n",
    "    model.add(Dense(3, activation='softmax'))\n",
    "    \n",
    "    model.compile(loss = 'categorical_crossentropy', optimizer = 'adam',metrics = ['accuracy'])\n",
    "    \n",
    "    if os.path.isfile(\"LSTMBestWeights.hdf5\"):\n",
    "        \n",
    "        #print(\"Hey\")\n",
    "        \n",
    "        model.load_weights(\"LSTMBestWeights.hdf5\")\n",
    "        \n",
    "        return model\n",
    "    else:\n",
    "        \n",
    "        print(\"Unable to find trained model\")\n",
    "        \n",
    "        return -1;\n",
    "    \n",
    "    \n",
    "def getTrained3OuptutModel(maxLengthParam):\n",
    "    \n",
    "    model = Sequential()\n",
    "    \n",
    "    #model.add(SpatialDropout1D(0.3))\n",
    "    \n",
    "    model.add(Flatten(batch_input_shape = (None,maxLengthParam,1)))\n",
    "    \n",
    "    model.add(Dense(50, activation = \"relu\"))\n",
    "    \n",
    "    model.add(Dropout(0.3, noise_shape=None, seed=None))\n",
    "    \n",
    "    model.add(Dense(25, activation = 'relu'))\n",
    "    \n",
    "    model.add(Dropout(0.3, noise_shape=None, seed=None))\n",
    "    \n",
    "    #model.add(SpatialDropout1D(0.3))\n",
    "    \n",
    "    model.add(Dense(12,activation = 'relu'))\n",
    "    \n",
    "    model.add(Dropout(0.3, noise_shape=None, seed=None))\n",
    "    \n",
    "    model.add(Dense(6,activation = 'relu'))\n",
    "    \n",
    "    model.add(Dropout(0.3, noise_shape=None, seed=None))\n",
    "    \n",
    "    model.add(Dense(3, activation='softmax'))\n",
    "    \n",
    "    model.compile(loss = 'categorical_crossentropy', optimizer = 'adam',metrics = ['accuracy'])\n",
    "    \n",
    "    if os.path.isfile(\"3OutputDNNBestWeights.hdf5\"):\n",
    "        \n",
    "        #print(\"Hey\")\n",
    "        \n",
    "        model.load_weights(\"3OutputDNNBestWeights.hdf5\")\n",
    "        \n",
    "        print(\"Returning Trained Model\")\n",
    "        \n",
    "        return model\n",
    "    else:\n",
    "        \n",
    "        print(\"Unable to find trained model\")\n",
    "        \n",
    "        return -1;\n",
    "    \n",
    "def getTrainedRL3OutputDNN(historyParam):\n",
    "    \n",
    "    usageInputLayer = keras.layers.Input(shape=(historyParam,1))\n",
    "    \n",
    "    flattened_layer = keras.layers.Flatten()(usageInputLayer)\n",
    "    \n",
    "    fullyConnected_0 = keras.layers.Dense(125, activation = 'relu',\n",
    "                    kernel_initializer='he_normal', kernel_regularizer=regularizers.l2(0.1))(flattened_layer)\n",
    "    \n",
    "    fullyConnected_1 = keras.layers.Dense(100, activation = 'relu',\n",
    "                    kernel_initializer='he_normal', kernel_regularizer=regularizers.l2(0.1))(fullyConnected_0)\n",
    "    \n",
    "    #drop1 = keras.layers.Dropout(0.25)(fullyConnected_1)\n",
    "    fullyConnected_2 = keras.layers.Dense(75, activation = 'relu',\n",
    "                    kernel_initializer='he_normal', kernel_regularizer=regularizers.l2(0.1))(fullyConnected_1)\n",
    "    \n",
    "    #drop2 = keras.layers.Dropout(0.25)(fullyConnected_2)\n",
    "    fullyConnected_3 = keras.layers.Dense(50, activation = 'relu',\n",
    "                    kernel_initializer='he_normal', kernel_regularizer=regularizers.l2(0.1))(fullyConnected_2)\n",
    "    \n",
    "    fullyConnected_4 = keras.layers.Dense(25, activation = 'relu',\n",
    "                    kernel_initializer='he_normal', kernel_regularizer=regularizers.l2(0.1))(fullyConnected_3)\n",
    "    \n",
    "    fullyConnected_5 = keras.layers.Dense(12, activation = 'relu',\n",
    "                    kernel_initializer='he_normal', kernel_regularizer=regularizers.l2(0.1))(fullyConnected_4)\n",
    "    \n",
    "    fullyConnected_6 = keras.layers.Dense(6, activation = 'relu',\n",
    "                    kernel_initializer='he_normal')(fullyConnected_5)\n",
    "    \n",
    "    softmax_output = keras.layers.Dense(3,activation='softmax')(fullyConnected_5)\n",
    "    \n",
    "    predictionModel = keras.models.Model(inputs=usageInputLayer,outputs=softmax_output)\n",
    "    \n",
    "    if os.path.isfile(\"3OutputRL3BestWeights.hdf5\"):\n",
    "        \n",
    "        #print(\"Hey\")\n",
    "        \n",
    "        predictionModel.load_weights(\"3OutputRL3BestWeights.hdf5\")\n",
    "        \n",
    "        print(\"Returning Trained Model\")\n",
    "        \n",
    "        return predictionModel\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        print(\"Unable to find trained model\")\n",
    "        \n",
    "        return -1;\n",
    "    \n",
    "def getTrainedRLLSTM(historyParam):\n",
    "    \n",
    "    usageInputLayer = keras.layers.Input(shape=(historyParam,1))\n",
    "    \n",
    "    #flattened_layer = keras.layers.Flatten()(usageInputLayer)\n",
    "    \n",
    "    LSTM_1 = keras.layers.LSTM((50), return_sequences = True)(usageInputLayer)\n",
    "    \n",
    "    full_connect_2 = keras.layers.Dense(50, activation = 'relu')(LSTM_1)\n",
    "    \n",
    "    LSTM_3 = keras.layers.LSTM(25, return_sequences = False)(full_connect_2)\n",
    "    \n",
    "    full_connect_3 = keras.layers.Dense(12, activation = 'relu')(LSTM_3)\n",
    "    \n",
    "    full_connect_4 = keras.layers.Dense(6, activation = 'relu')(full_connect_3)\n",
    "    \n",
    "    softmax_output = keras.layers.Dense(3,activation='softmax')(full_connect_4)\n",
    "    \n",
    "    predictionModel = keras.models.Model(inputs=usageInputLayer,outputs=softmax_output)\n",
    "    \n",
    "    if os.path.isfile(\"LSTMV2RLBestWeights.hdf5\"):\n",
    "        \n",
    "        #print(\"Hey\")\n",
    "        \n",
    "        predictionModel.load_weights(\"LSTMV2RLBestWeights.hdf5\")\n",
    "        \n",
    "        print(\"Returning Trained Model\")\n",
    "        \n",
    "        return predictionModel\n",
    "    else:\n",
    "        \n",
    "        print(\"Unable to find trained model\")\n",
    "        \n",
    "        return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def appendToList(oldList,newList,maxLength):\n",
    "    \n",
    "    #append to the new entries\n",
    "    oldList = np.insert(oldList,0,np.array([newList]),axis = 0)\n",
    "    \n",
    "    #Remove oldest row if there are more than 50 entries\n",
    "    if(oldList.shape[0]>maxLength):\n",
    "        oldList = oldList[:49,:]\n",
    "\n",
    "    return oldList\n",
    "\n",
    "def getPredictionsForOneTimeStep(model,usageList,maxLengthParam):\n",
    "    \n",
    "    currUsageList = cpuinfo()\n",
    "    \n",
    "    updatedList = appendToList(usageList,currUsageList,maxLengthParam)\n",
    "    \n",
    "    predictions = []\n",
    "    \n",
    "    predDict = {0:0,1:1,2:-1}\n",
    "    \n",
    "    for i in range(updatedList.shape[1]):\n",
    "        \n",
    "        if updatedList.shape[0]==maxLengthParam:\n",
    "            \n",
    "            modelOutput = model.predict(np.expand_dims(np.expand_dims(updatedList[:,i],axis = 1),axis = 0))\n",
    "\n",
    "            modelPrediction = predDict[np.argmax(modelOutput)]\n",
    "\n",
    "            predictions.append(modelPrediction)\n",
    "        \n",
    "        else:\n",
    "            \n",
    "            predictions.append(0)\n",
    "    \n",
    "    return predictions, updatedList\n",
    "\n",
    "#overProvisionedList = \n",
    "\n",
    "def getRightOutputs(usageList,minThreshold, maxThreshold):\n",
    "    \n",
    "    currList = usageList[0,:]\n",
    "    print(currList)\n",
    "    \n",
    "    target = []\n",
    "    \n",
    "    for i in range(usageList.shape[1]):\n",
    "        if currList[i] > maxThreshold:# Scale Up\n",
    "            #print(\"MaxThres \",maxThreshold,\" \",currList[i])\n",
    "            target.append(1)\n",
    "        elif currList[i] < minThreshold: # Scale Down\n",
    "            #print(\"MinThres \",minThreshold,\" \",currList[i])\n",
    "            target.append(-1)\n",
    "        else:\n",
    "            #print(\"Same \",currList[i])\n",
    "            target.append(0)  #Remain same\n",
    "    \n",
    "    return target\n",
    "\n",
    "def getVirtualMachineCPU():\n",
    "    \n",
    "    availableVirtualMachineCPU = 10\n",
    "    \n",
    "    return availableVirtualMachineCPU\n",
    "\n",
    "def getPercentagesBasedOnPredictions(predictions, usageArray, minThreshold, maxThreshold):\n",
    "    \n",
    "    underProvisionedContainers = [i for i in range(usageArray[0,:].shape[1])  if usageArray[0,i]>maxThreshold]\n",
    "    \n",
    "    overProvisionedContainers = [i for i in range(usageArray[0,:].shape[1])  if usageArray[0,i]<minThreshold]\n",
    "    \n",
    "    rightlyProvisionedContainers = [i for i in range(usageArray[0,:].shape[1])  if usageArray[0,i]>=minThreshold and usageArray[0,i]<=maxThreshold]\n",
    "    \n",
    "    availableVCPU = getVirtualMachineCPU()\n",
    "    \n",
    "    VCPUSplit = 0\n",
    "    \n",
    "    percentArray = np.zeros(len(predictions))\n",
    "    \n",
    "    if len(overProvisionedContainers)>0:\n",
    "        \n",
    "        availableVCPU = availableVCPU + len(overProvisionedContainers) * 10\n",
    "        \n",
    "        for i in overProvisionedContainers:\n",
    "            \n",
    "            percentArray[i] = -10\n",
    "    \n",
    "    #if len(rightlyProvisioned)>0:\n",
    "        #availableVCPU = availableVCPU + len(rightlyProvisioned) * 5\n",
    "        \n",
    "    if availableVCPU>0 and len(underProvisionedContainers)>0:\n",
    "        \n",
    "        if len(underProvisionedContainers)*10>availableVCPU:\n",
    "            \n",
    "            for i in rightlyProvisionedContainers:\n",
    "                \n",
    "                percentArray[i] = -5\n",
    "                \n",
    "                availableVCPU += 5\n",
    "                \n",
    "                if (availableVCPU < len(underProvisionedContainers)*10):\n",
    "                    \n",
    "                    break\n",
    "        \n",
    "            VCPUSplit = availableVCPU/len(underProvisionedContainers)\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            VCPUSplit = 10\n",
    "        \n",
    "        for i in underProvisionedContainers:\n",
    "                \n",
    "                percentArray[i] = VCPUSplit\n",
    "        \n",
    "    \n",
    "    return percentArray\n",
    "        \n",
    "\n",
    "def callAPIWithPredictions(predictions,URL):\n",
    "\n",
    "    headers = {\n",
    "        'Content-Type': 'application/json',\n",
    "    }\n",
    "\n",
    "    data = '{\"predictions\":['+ ','.join(str(num) for num in predictions) +']}'\n",
    "    print(data)\n",
    "    response = requests.post(URL, headers=headers, data=data)\n",
    "    \n",
    "\n",
    "    \n",
    "class Prediction():\n",
    "    def __init__(self, model, maxLengthParam,containerCount,minThreshold, maxThreshold):\n",
    "        self.usageArray = np.empty(shape = (0,containerCount))\n",
    "        self.correctOutputArray = np.empty(shape = (0,containerCount))\n",
    "        self.predictionsArray = np.empty(shape = (0,containerCount))\n",
    "        self.model = model\n",
    "        self.maxLengthParam = maxLengthParam\n",
    "        self.minThreshold = minThreshold\n",
    "        self.maxThreshold = maxThreshold\n",
    "    \n",
    "    def generatePredictions(self): \n",
    "        predictions,self.usageArray = getPredictionsForOneTimeStep(self.model,self.usageArray,self.maxLengthParam)       \n",
    "        self.predictionsArray = appendToList(self.predictionsArray, predictions, self.maxLengthParam)\n",
    "        if(self.usageArray.shape[0]==self.maxLengthParam):\n",
    "            correctOutputsList = getRightOutputs(self.usageArray,self.minThreshold, self.maxThreshold)\n",
    "            self.correctOutputArray = appendToList(self.correctOutputArray, correctOutputsList, self.maxLengthParam)\n",
    "            print(\"Predictions: \",predictions)        \n",
    "            print(\"Expected Outputs: \",correctOutputsList)            \n",
    "            callAPIWithPredictions(predictions,\"http://152.46.16.197:5000/changeVCPU\")\n",
    "            print(accuracy_score(predictions,correctOutputsList))\n",
    "    \n",
    "# def generatePredictions(model, maxLengthParam,containerCount,minThreshold, maxThreshold):\n",
    "    \n",
    "#     usageArray = np.empty(shape = (0,containerCount))\n",
    "    \n",
    "#     cnt = 0;\n",
    "    \n",
    "#     correctOutputArray = np.empty(shape = (0,containerCount))\n",
    "    \n",
    "#     predictionsArray = np.empty(shape = (0,containerCount))\n",
    "    \n",
    "#     while cnt<80:\n",
    "        \n",
    "#         predictions,usageArray = getPredictionsForOneTimeStep(model,usageArray,maxLengthParam)\n",
    "        \n",
    "#         predictionsArray = appendToList(predictionsArray, predictions, maxLengthParam)\n",
    "        \n",
    "        \n",
    "#         if(usageArray.shape[0]==maxLengthParam):\n",
    "    \n",
    "#             correctOutputsList = getRightOutputs(usageArray,minThreshold, maxThreshold)\n",
    "\n",
    "#             correctOutputArray = appendToList(correctOutputArray, correctOutputsList, maxLengthParam)\n",
    "            \n",
    "#             print(\"Predictions: \",predictions)\n",
    "            \n",
    "#             print(\"Expected Outputs: \",correctOutputsList)\n",
    "            \n",
    "#             callAPIWithPredictions(predictions,\"http://152.46.19.96:5000/changeVCPU\")\n",
    "            \n",
    "#             print(accuracy_score(predictions,correctOutputsList))\n",
    "            \n",
    "#             #percentArray = getPercentagesBasedOnPredictions(predictions,usageArray,minThreshold, maxThreshold)\n",
    "            \n",
    "#             #print(\"Percentage Changes\",percentArray)\n",
    "#             #for i in range(usageArray.shape[1]):\n",
    "\n",
    "#                 #correctOutputsForTraining = to_categorical(correctOutputs,num_classes = 3)\n",
    "        \n",
    "#         cnt+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Returning Trained Model\n",
      "Returning Trained Model\n"
     ]
    }
   ],
   "source": [
    "LSTMModel = getTrainedLSTMModel(50)\n",
    "RLLSTMModel = getTrainedRLLSTM(50)\n",
    "RL3OutputDNNModel = getTrainedRL3OutputDNN(50)\n",
    "DQNModel = getDQNModel(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected dense_64_input to have 2 dimensions, but got array with shape (1, 50, 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-1f3cfaa1dd48>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPrediction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDQNModel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m70\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgeneratePredictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-7-a07acbb6a020>\u001b[0m in \u001b[0;36mgeneratePredictions\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgeneratePredictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m         \u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musageArray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetPredictionsForOneTimeStep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musageArray\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaxLengthParam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictionsArray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mappendToList\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictionsArray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaxLengthParam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musageArray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaxLengthParam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-a07acbb6a020>\u001b[0m in \u001b[0;36mgetPredictionsForOneTimeStep\u001b[0;34m(model, usageList, maxLengthParam)\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mupdatedList\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mmaxLengthParam\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m             \u001b[0mmodelOutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mupdatedList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0mmodelPrediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodelOutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m   1147\u001b[0m                              'argument.')\n\u001b[1;32m   1148\u001b[0m         \u001b[0;31m# Validate user data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1149\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_standardize_user_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1150\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstateful\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    749\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 751\u001b[0;31m             exception_prefix='input')\n\u001b[0m\u001b[1;32m    752\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    126\u001b[0m                         \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m                         \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' dimensions, but got array '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m                         'with shape ' + str(data_shape))\n\u001b[0m\u001b[1;32m    129\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m                     \u001b[0mdata_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected dense_64_input to have 2 dimensions, but got array with shape (1, 50, 1)"
     ]
    }
   ],
   "source": [
    "temp = cpuinfo()\n",
    "test = Prediction(DQNModel,50,len(temp),30,70)\n",
    "for i in range(50):\n",
    "    test.generatePredictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sched = BackgroundScheduler()\n",
    "sched.add_job(test.generatePredictions, 'interval', seconds=2)\n",
    "sched.start()\n",
    "print(datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sched.shutdown() # shutdown the scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mylist = np.array([cpuinfo()])\n",
    "print(mylist)\n",
    "print(mylist.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mylist2 = np.insert(mylist,0, np.array([cpuinfo()]), axis = 0)\n",
    "print(mylist2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mylist = np.append(np.empty(shape = (0,5)), np.array([cpuinfo()]), axis = 0)\n",
    "print(mylist)\n",
    "print(mylist.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mylist[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [1,2,3,4]\n",
    "a[1:]\n",
    "','.join(str(e) for e in a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = np.random.randint(1,100,size = (10,5))\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.expand_dims(np.expand_dims(b[:,1],axis = 1),axis = 0).shape\n",
    "#b[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.zeros(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p36)",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
