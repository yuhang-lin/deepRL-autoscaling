{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Input\n",
    "from keras.layers import LSTM, SpatialDropout1D \n",
    "from sklearn.model_selection import train_test_split\n",
    "import csv\n",
    "import keras\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Raw Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "inpData = []\n",
    "labels = []\n",
    "with open('cdata.csv') as csv_file:\n",
    "    lines = csv.reader(csv_file, delimiter=',')\n",
    "    for row in lines:\n",
    "        labels.append(row[0])\n",
    "        inpData.append(float(row[1]))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set the Target Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "minThreshold = 30\n",
    "maxThreshold = 70\n",
    "target = []\n",
    "index = 0\n",
    "while index + 1 < len(inpData):\n",
    "    if inpData[index + 1] > maxThreshold:# Scale Up\n",
    "        target.append(1)\n",
    "    elif inpData[index + 1] < minThreshold: # Scale Down\n",
    "        target.append(-1)\n",
    "    else:\n",
    "        target.append(0)  #Remain same\n",
    "    index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing Input Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpuUsage = []\n",
    "cpuScaling = []\n",
    "historyParam = 50\n",
    "index = historyParam\n",
    "\n",
    "while index<len(inpData):\n",
    "    currRec = [[inpData[i]] for i in range(index-historyParam,index)]\n",
    "    cpuUsage.append(currRec)\n",
    "    index+=1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpuScaling = target[historyParam-1:len(target)]\n",
    "\n",
    "\n",
    "cpuUsageData = np.array(cpuUsage,dtype = 'float')\n",
    "cpuScaling = np.array(cpuScaling,dtype = 'float')\n",
    "\n",
    "cpuScalingCategorical = to_categorical(cpuScaling, num_classes = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(inpData)\n",
    "X_train, X_test, y_train, y_test = train_test_split(cpuUsageData , cpuScalingCategorical, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpuUsageData.shape\n",
    "#np.shape(cpuUsage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 1.]\n",
      "-1.0\n",
      "set([0.0, 1.0, -1.0])\n",
      "-1.0    4121\n",
      " 0.0     523\n",
      " 1.0     391\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "testrec = 5\n",
    "print(cpuScalingCategorical[testrec])\n",
    "print(cpuScaling[testrec])\n",
    "print(set(cpuScaling))\n",
    "myseries=pandas.Series(cpuScaling)\n",
    "print(myseries.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p27/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p27/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "#model.add(SpatialDropout1D(0.3))\n",
    "model.add(LSTM((50),dropout = 0.3,batch_input_shape = (None,50,1), return_sequences = True))\n",
    "model.add(Dense(50, activation = 'tanh'))\n",
    "#model.add(SpatialDropout1D(0.3))\n",
    "model.add(LSTM(25,return_sequences = False))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer = 'adam',metrics = ['accuracy'])\n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 50, 50)            10400     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 50, 50)            2550      \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 25)                7600      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3)                 78        \n",
      "=================================================================\n",
      "Total params: 20,628\n",
      "Trainable params: 20,628\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath=\"LSTMBestWeights.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hey\n"
     ]
    }
   ],
   "source": [
    "if os.path.isfile(\"LSTMBestWeights.hdf5\"):\n",
    "    #print(\"Hey\")\n",
    "    model.load_weights(\"LSTMBestWeights.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p27/lib/python2.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.85703, saving model to LSTMBestWeights.hdf5\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.85703 to 0.86021, saving model to LSTMBestWeights.hdf5\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.86021 to 0.89913, saving model to LSTMBestWeights.hdf5\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.89913 to 0.92851, saving model to LSTMBestWeights.hdf5\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.92851\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.92851 to 0.93169, saving model to LSTMBestWeights.hdf5\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.93169\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.93169\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.93169\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.93169\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.93169\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.93169\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.93169\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.93169\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.93169\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.93169\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.93169\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.93169\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.93169\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.93169\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.93169\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.93169\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.93169\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.93169\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.93169\n",
      "\n",
      "Epoch 00026: val_acc did not improve from 0.93169\n",
      "\n",
      "Epoch 00027: val_acc did not improve from 0.93169\n",
      "\n",
      "Epoch 00028: val_acc did not improve from 0.93169\n",
      "\n",
      "Epoch 00029: val_acc did not improve from 0.93169\n",
      "\n",
      "Epoch 00030: val_acc did not improve from 0.93169\n",
      "\n",
      "Epoch 00031: val_acc did not improve from 0.93169\n",
      "\n",
      "Epoch 00032: val_acc did not improve from 0.93169\n",
      "\n",
      "Epoch 00033: val_acc did not improve from 0.93169\n",
      "\n",
      "Epoch 00034: val_acc did not improve from 0.93169\n",
      "\n",
      "Epoch 00035: val_acc did not improve from 0.93169\n",
      "\n",
      "Epoch 00036: val_acc did not improve from 0.93169\n",
      "\n",
      "Epoch 00037: val_acc did not improve from 0.93169\n",
      "\n",
      "Epoch 00038: val_acc did not improve from 0.93169\n",
      "\n",
      "Epoch 00039: val_acc did not improve from 0.93169\n",
      "\n",
      "Epoch 00040: val_acc did not improve from 0.93169\n",
      "\n",
      "Epoch 00041: val_acc did not improve from 0.93169\n",
      "\n",
      "Epoch 00042: val_acc did not improve from 0.93169\n",
      "\n",
      "Epoch 00043: val_acc did not improve from 0.93169\n",
      "\n",
      "Epoch 00044: val_acc did not improve from 0.93169\n",
      "\n",
      "Epoch 00045: val_acc did not improve from 0.93169\n",
      "\n",
      "Epoch 00046: val_acc did not improve from 0.93169\n",
      "\n",
      "Epoch 00047: val_acc did not improve from 0.93169\n",
      "\n",
      "Epoch 00048: val_acc did not improve from 0.93169\n",
      "\n",
      "Epoch 00049: val_acc did not improve from 0.93169\n",
      "\n",
      "Epoch 00050: val_acc did not improve from 0.93169\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs = 50,validation_data = [X_test, y_test], callbacks = callbacks_list,verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 50, 1)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape\n",
    "np.expand_dims(X_test[0],axis = 0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = model.predict(np.expand_dims(X_test[0],axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7.9184992e-04 6.0061505e-04 9.9860758e-01]]\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "print(res)\n",
    "print(np.argmax(res[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax([0,1,0],axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(res,axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(inpData[0+1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p27)",
   "language": "python",
   "name": "conda_tensorflow_p27"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
