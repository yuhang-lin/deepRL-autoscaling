{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Input\n",
    "from keras.layers import LSTM, SpatialDropout1D \n",
    "from sklearn.model_selection import train_test_split\n",
    "import csv\n",
    "import keras\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import os\n",
    "#from getcpuinfo import cpuinfo\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "from apscheduler.schedulers.background import BackgroundScheduler\n",
    "import datetime\n",
    "from keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.insert(0, os.path.abspath('..'))\n",
    "from apis.getcpuinfo import cpuinfo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTrainedLSTMModel(maxLengthParam):\n",
    "    \n",
    "    model = Sequential()\n",
    "    \n",
    "    #model.add(SpatialDropout1D(0.3))\n",
    "    \n",
    "    model.add(LSTM((50),dropout = 0.3,batch_input_shape = (None,50,1), return_sequences = True))\n",
    "    \n",
    "    model.add(Dense(25, activation = 'relu',\n",
    "                        kernel_initializer='he_normal', kernel_regularizer=regularizers.l2(0.1)))\n",
    "    \n",
    "    model.add(LSTM(25,return_sequences = False))\n",
    "    \n",
    "    model.add(Dense(12, activation = 'relu',\n",
    "                        kernel_initializer='he_normal', kernel_regularizer=regularizers.l2(0.1)))\n",
    "    \n",
    "    model.add(Dropout(rate = 0.3))\n",
    "    \n",
    "    model.add(Dense(6, activation = 'relu',\n",
    "                        kernel_initializer='he_normal', kernel_regularizer=regularizers.l2(0.1)))\n",
    "    \n",
    "    model.add(Dense(3, activation='softmax', kernel_initializer='he_normal'))\n",
    "    \n",
    "    model.compile(loss = 'categorical_crossentropy', optimizer = 'adam',metrics = ['accuracy'])\n",
    "    \n",
    "    if os.path.isfile(\"SimpleLSTMV4BestWeights.hdf5\"):\n",
    "        \n",
    "        #print(\"Hey\")\n",
    "        \n",
    "        model.load_weights(\"SimpleLSTMV4BestWeights.hdf5\")\n",
    "        \n",
    "        return model\n",
    "    else:\n",
    "        \n",
    "        print(\"Unable to find trained model\")\n",
    "        \n",
    "        return -1;\n",
    "    \n",
    "    \n",
    "def getTrained3OuptutModel(maxLengthParam):\n",
    "    \n",
    "    model = Sequential()\n",
    "    #model.add(SpatialDropout1D(0.3))\n",
    "    model.add(Flatten(batch_input_shape = (None,50,1)))\n",
    "\n",
    "    model.add(Dense(50, activation = 'relu',\n",
    "                        kernel_initializer='he_normal', kernel_regularizer=regularizers.l2(0.1)))\n",
    "\n",
    "    model.add(Dropout(0.3, noise_shape=None, seed=None))\n",
    "\n",
    "    model.add(Dense(25, activation = 'relu',\n",
    "                        kernel_initializer='he_normal', kernel_regularizer=regularizers.l2(0.1)))\n",
    "\n",
    "    model.add(Dropout(0.3, noise_shape=None, seed=None))\n",
    "\n",
    "    #model.add(SpatialDropout1D(0.3))\n",
    "    model.add(Dense(12,activation = 'relu',\n",
    "                        kernel_initializer='he_normal', kernel_regularizer=regularizers.l2(0.1)))\n",
    "\n",
    "    model.add(Dropout(0.3, noise_shape=None, seed=None))\n",
    "\n",
    "    model.add(Dense(6,activation = 'relu',\n",
    "                        kernel_initializer='he_normal', kernel_regularizer=regularizers.l2(0.1)))\n",
    "\n",
    "    model.add(Dropout(0.3, noise_shape=None, seed=None))\n",
    "\n",
    "    model.add(Dense(3, activation='softmax',kernel_initializer='he_normal'))\n",
    "\n",
    "    model.compile(loss = 'categorical_crossentropy', optimizer = 'adam',metrics = ['accuracy'])\n",
    "    \n",
    "    if os.path.isfile(\"3OutputDNNV2BestWeights.hdf5\"):\n",
    "        \n",
    "        #print(\"Hey\")\n",
    "        \n",
    "        model.load_weights(\"3OutputDNNV2BestWeights.hdf5\")\n",
    "        \n",
    "        print(\"Returning Trained Model\")\n",
    "        \n",
    "        return model\n",
    "    else:\n",
    "        \n",
    "        print(\"Unable to find trained model\")\n",
    "        \n",
    "        return -1;\n",
    "    \n",
    "def getTrainedRL3OutputDNN(historyParam):\n",
    "    \n",
    "    usageInputLayer = keras.layers.Input(shape=(historyParam,1))\n",
    "    \n",
    "    flattened_layer = keras.layers.Flatten()(usageInputLayer)\n",
    "    \n",
    "    '''fullyConnected_0 = keras.layers.Dense(125, activation = 'relu',\n",
    "                    kernel_initializer='he_normal', kernel_regularizer=regularizers.l2(0.1))(flattened_layer)'''\n",
    "    \n",
    "    fullyConnected_1 = keras.layers.Dense(50, activation = 'relu',\n",
    "                    kernel_initializer='he_normal', kernel_regularizer=regularizers.l2(0.1))(flattened_layer)\n",
    "    \n",
    "    #drop1 = keras.layers.Dropout(0.25)(fullyConnected_1)\n",
    "    \n",
    "    fullyConnected_2 = keras.layers.Dense(50, activation = 'relu',\n",
    "                    kernel_initializer='he_normal', kernel_regularizer=regularizers.l2(0.1))(fullyConnected_1)\n",
    "    \n",
    "    #drop2 = keras.layers.Dropout(0.25)(fullyConnected_2)\n",
    "    \n",
    "    fullyConnected_3 = keras.layers.Dense(50, activation = 'relu',\n",
    "                    kernel_initializer='he_normal', kernel_regularizer=regularizers.l2(0.1))(fullyConnected_2)\n",
    "    \n",
    "    fullyConnected_4 = keras.layers.Dense(25, activation = 'relu',\n",
    "                    kernel_initializer='he_normal', kernel_regularizer=regularizers.l2(0.1))(fullyConnected_3)\n",
    "    \n",
    "    fullyConnected_5 = keras.layers.Dense(12, activation = 'relu',\n",
    "                    kernel_initializer='he_normal', kernel_regularizer=regularizers.l2(0.1))(fullyConnected_4)\n",
    "    \n",
    "    fullyConnected_6 = keras.layers.Dense(6, activation = 'relu',\n",
    "                    kernel_initializer='he_normal',kernel_regularizer=regularizers.l2(0.1))(fullyConnected_5)\n",
    "    \n",
    "    softmax_output = keras.layers.Dense(3,activation='softmax',kernel_initializer='he_normal')(fullyConnected_6)\n",
    "    \n",
    "    predictionModel = keras.models.Model(inputs=usageInputLayer,outputs=softmax_output)\n",
    "    \n",
    "    if os.path.isfile(\"3OutputRLV4BestWeights.hdf5\"):\n",
    "        \n",
    "        #print(\"Hey\")\n",
    "        \n",
    "        predictionModel.load_weights(\"3OutputRLV4BestWeights.hdf5\")\n",
    "        \n",
    "        print(\"Returning Trained Model\")\n",
    "        \n",
    "        return predictionModel\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        print(\"Unable to find trained model\")\n",
    "        \n",
    "        return -1;\n",
    "    \n",
    "def getTrainedRLLSTM(historyParam):\n",
    "    \n",
    "    usageInputLayer = keras.layers.Input(shape=(historyParam,1))\n",
    "    \n",
    "    #flattened_layer = keras.layers.Flatten()(usageInputLayer)\n",
    "    \n",
    "    LSTM_1 = keras.layers.LSTM((50), return_sequences = True)(usageInputLayer)\n",
    "    \n",
    "    full_connect_2 = keras.layers.Dense(25, activation = 'relu',kernel_initializer='he_normal')(LSTM_1)\n",
    "    \n",
    "    LSTM_3 = keras.layers.LSTM(25, return_sequences = False)(full_connect_2)\n",
    "    \n",
    "    full_connect_3 = keras.layers.Dense(12, activation = 'relu',kernel_initializer='he_normal')(LSTM_3)\n",
    "    \n",
    "    full_connect_4 = keras.layers.Dense(6, activation = 'relu',kernel_initializer='he_normal')(full_connect_3)\n",
    "    \n",
    "    softmax_output = keras.layers.Dense(3,activation='softmax',kernel_initializer='he_normal')(full_connect_4)\n",
    "    \n",
    "    predictionModel = keras.models.Model(inputs=usageInputLayer,outputs=softmax_output)\n",
    "    \n",
    "    if os.path.isfile(\"LSTMV3RLBestWeights.hdf5\"):\n",
    "        \n",
    "        #print(\"Hey\")\n",
    "        \n",
    "        predictionModel.load_weights(\"LSTMV3RLBestWeights.hdf5\")\n",
    "        \n",
    "        print(\"Returning Trained Model\")\n",
    "        \n",
    "        return predictionModel\n",
    "    else:\n",
    "        \n",
    "        print(\"Unable to find trained model\")\n",
    "        \n",
    "        return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def appendToList(oldList,newList,maxLength):\n",
    "    \n",
    "    #append to the new entries\n",
    "    #oldList = np.insert(oldList,0,np.array([newList]),axis = 0)\n",
    "    oldList = np.append(oldList,np.array([newList]),axis = 0)\n",
    "    #Remove oldest row if there are more than 50 entries\n",
    "    if(oldList.shape[0]>maxLength):\n",
    "        oldList = oldList[1:,:]\n",
    "    #print(oldList)\n",
    "    return oldList\n",
    "\n",
    "def getPredictionsForOneTimeStep(model,usageList,maxLengthParam):\n",
    "    \n",
    "    currUsageList = cpuinfo()\n",
    "    \n",
    "    updatedList = appendToList(usageList,currUsageList,maxLengthParam)\n",
    "    \n",
    "    predictions = []\n",
    "    \n",
    "    predDict = {0:0,1:1,2:-1}\n",
    "    \n",
    "    for i in range(updatedList.shape[1]):\n",
    "        \n",
    "        if updatedList.shape[0]==maxLengthParam:\n",
    "            \n",
    "            modelOutput = model.predict(np.expand_dims(np.expand_dims(updatedList[:,i],axis = 1),axis = 0))\n",
    "            \n",
    "            print(modelOutput)\n",
    "\n",
    "            modelPrediction = predDict[np.argmax(modelOutput)]\n",
    "\n",
    "            predictions.append(modelPrediction)\n",
    "        \n",
    "        else:\n",
    "            \n",
    "            predictions.append(0)\n",
    "    \n",
    "    return predictions, updatedList\n",
    "\n",
    "#overProvisionedList = \n",
    "\n",
    "def getRightOutputs(usageList,minThreshold, maxThreshold):\n",
    "    \n",
    "    currList = usageList[0,:]\n",
    "    print(currList)\n",
    "    \n",
    "    target = []\n",
    "    \n",
    "    for i in range(usageList.shape[1]):\n",
    "        if currList[i] > maxThreshold:# Scale Up\n",
    "            #print(\"MaxThres \",maxThreshold,\" \",currList[i])\n",
    "            target.append(1)\n",
    "        elif currList[i] < minThreshold: # Scale Down\n",
    "            #print(\"MinThres \",minThreshold,\" \",currList[i])\n",
    "            target.append(-1)\n",
    "        else:\n",
    "            #print(\"Same \",currList[i])\n",
    "            target.append(0)  #Remain same\n",
    "    \n",
    "    return target\n",
    "\n",
    "def getVirtualMachineCPU():\n",
    "    \n",
    "    availableVirtualMachineCPU = 10\n",
    "    \n",
    "    return availableVirtualMachineCPU\n",
    "\n",
    "def getPercentagesBasedOnPredictions(predictions, usageArray, minThreshold, maxThreshold):\n",
    "    \n",
    "    underProvisionedContainers = [i for i in range(usageArray[0,:].shape[1])  if usageArray[0,i]>maxThreshold]\n",
    "    \n",
    "    overProvisionedContainers = [i for i in range(usageArray[0,:].shape[1])  if usageArray[0,i]<minThreshold]\n",
    "    \n",
    "    rightlyProvisionedContainers = [i for i in range(usageArray[0,:].shape[1])  if usageArray[0,i]>=minThreshold and usageArray[0,i]<=maxThreshold]\n",
    "    \n",
    "    availableVCPU = getVirtualMachineCPU()\n",
    "    \n",
    "    VCPUSplit = 0\n",
    "    \n",
    "    percentArray = np.zeros(len(predictions))\n",
    "    \n",
    "    if len(overProvisionedContainers)>0:\n",
    "        \n",
    "        availableVCPU = availableVCPU + len(overProvisionedContainers) * 10\n",
    "        \n",
    "        for i in overProvisionedContainers:\n",
    "            \n",
    "            percentArray[i] = -10\n",
    "    \n",
    "    #if len(rightlyProvisioned)>0:\n",
    "        #availableVCPU = availableVCPU + len(rightlyProvisioned) * 5\n",
    "        \n",
    "    if availableVCPU>0 and len(underProvisionedContainers)>0:\n",
    "        \n",
    "        if len(underProvisionedContainers)*10>availableVCPU:\n",
    "            \n",
    "            for i in rightlyProvisionedContainers:\n",
    "                \n",
    "                percentArray[i] = -5\n",
    "                \n",
    "                availableVCPU += 5\n",
    "                \n",
    "                if (availableVCPU < len(underProvisionedContainers)*10):\n",
    "                    \n",
    "                    break\n",
    "        \n",
    "            VCPUSplit = availableVCPU/len(underProvisionedContainers)\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            VCPUSplit = 10\n",
    "        \n",
    "        for i in underProvisionedContainers:\n",
    "                \n",
    "                percentArray[i] = VCPUSplit\n",
    "        \n",
    "    \n",
    "    return percentArray\n",
    "        \n",
    "\n",
    "def callAPIWithPredictions(predictions,URL):\n",
    "\n",
    "    headers = {\n",
    "        'Content-Type': 'application/json',\n",
    "    }\n",
    "\n",
    "    data = '{\"predictions\":['+ ','.join(str(num) for num in predictions) +']}'\n",
    "    print(data)\n",
    "    response = requests.post(URL, headers=headers, data=data)\n",
    "    \n",
    "\n",
    "    \n",
    "class Prediction():\n",
    "    def __init__(self, model, maxLengthParam,containerCount,minThreshold, maxThreshold):\n",
    "        self.usageArray = np.empty(shape = (0,containerCount))\n",
    "        self.correctOutputArray = np.empty(shape = (0,containerCount))\n",
    "        self.predictionsArray = np.empty(shape = (0,containerCount))\n",
    "        self.model = model\n",
    "        self.maxLengthParam = maxLengthParam\n",
    "        self.minThreshold = minThreshold\n",
    "        self.maxThreshold = maxThreshold\n",
    "        self.lastPredictions = [-1, -1, -1, -1]\n",
    "        self.accuracy_list = []\n",
    "    \n",
    "    def generatePredictions(self): \n",
    "        predictions,self.usageArray = getPredictionsForOneTimeStep(self.model,self.usageArray,self.maxLengthParam)       \n",
    "        self.predictionsArray = appendToList(self.predictionsArray, predictions, self.maxLengthParam)\n",
    "        if (self.usageArray.shape[0]==self.maxLengthParam):\n",
    "            correctOutputsList = getRightOutputs(self.usageArray,self.minThreshold, self.maxThreshold)\n",
    "            self.correctOutputArray = appendToList(self.correctOutputArray, correctOutputsList, self.maxLengthParam)\n",
    "            print(\"Last expected Outputs: \",correctOutputsList) \n",
    "            accuracy = accuracy_score(self.lastPredictions,correctOutputsList)\n",
    "            print(accuracy)\n",
    "            self.accuracy_list.append(accuracy)\n",
    "            print(\"Predictions: \",predictions)            \n",
    "            callAPIWithPredictions(predictions,\"http://152.46.16.189:5000/changeVCPU\")\n",
    "            self.lastPredictions = predictions\n",
    "            \n",
    "    \n",
    "# def generatePredictions(model, maxLengthParam,containerCount,minThreshold, maxThreshold):\n",
    "    \n",
    "#     usageArray = np.empty(shape = (0,containerCount))\n",
    "    \n",
    "#     cnt = 0;\n",
    "    \n",
    "#     correctOutputArray = np.empty(shape = (0,containerCount))\n",
    "    \n",
    "#     predictionsArray = np.empty(shape = (0,containerCount))\n",
    "    \n",
    "#     while cnt<80:\n",
    "        \n",
    "#         predictions,usageArray = getPredictionsForOneTimeStep(model,usageArray,maxLengthParam)\n",
    "        \n",
    "#         predictionsArray = appendToList(predictionsArray, predictions, maxLengthParam)\n",
    "        \n",
    "        \n",
    "#         if(usageArray.shape[0]==maxLengthParam):\n",
    "    \n",
    "#             correctOutputsList = getRightOutputs(usageArray,minThreshold, maxThreshold)\n",
    "\n",
    "#             correctOutputArray = appendToList(correctOutputArray, correctOutputsList, maxLengthParam)\n",
    "            \n",
    "#             print(\"Predictions: \",predictions)\n",
    "            \n",
    "#             print(\"Expected Outputs: \",correctOutputsList)\n",
    "            \n",
    "#             callAPIWithPredictions(predictions,\"http://152.46.19.96:5000/changeVCPU\")\n",
    "            \n",
    "#             print(accuracy_score(predictions,correctOutputsList))\n",
    "            \n",
    "#             #percentArray = getPercentagesBasedOnPredictions(predictions,usageArray,minThreshold, maxThreshold)\n",
    "            \n",
    "#             #print(\"Percentage Changes\",percentArray)\n",
    "#             #for i in range(usageArray.shape[1]):\n",
    "\n",
    "#                 #correctOutputsForTraining = to_categorical(correctOutputs,num_classes = 3)\n",
    "        \n",
    "#         cnt+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_line_graph(data):\n",
    "    fig = plt.gcf()\n",
    "    #fig.set_size_inches(18.5, 10.5)\n",
    "    t = np.arange(0.01, len(data), 1)\n",
    "    plt.plot(t, data) \n",
    "    # make these tick labels visible\n",
    "    plt.setp(ax1.get_xticklabels(), visible=True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LSTMModel = getTrainedLSTMModel(50)\n",
    "RLLSTMModel = getTrainedRLLSTM(50)\n",
    "RL3OutputDNNModel = getTrainedRL3OutputDNN(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "temp = cpuinfo()\n",
    "test = Prediction(RLLSTMModel,50,len(temp),30,70)\n",
    "for i in range(51):\n",
    "    test.generatePredictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sched = BackgroundScheduler()\n",
    "sched.add_job(test.generatePredictions, 'interval', seconds=2)\n",
    "sched.start()\n",
    "print(datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_line_graph(test.accuracy_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sched.shutdown() # shutdown the scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mylist = np.array([cpuinfo()])\n",
    "print(mylist)\n",
    "print(mylist.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mylist2 = np.insert(mylist,0, np.array([cpuinfo()]), axis = 0)\n",
    "print(mylist2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mylist = np.append(np.empty(shape = (0,5)), np.array([cpuinfo()]), axis = 0)\n",
    "print(mylist)\n",
    "print(mylist.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mylist[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [1,2,3,4]\n",
    "a[1:]\n",
    "','.join(str(e) for e in a)\n",
    "print(\"hey\",a[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = np.random.randint(1,100,size = (10,5))\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.expand_dims(np.expand_dims(b[:,1],axis = 1),axis = 0).shape\n",
    "#b[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.zeros(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callAPIWithPredictions([0,0,0,0],\"http://152.46.19.80:5000/changeVCPU\")\n",
    "cpuinfo()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p36)",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
